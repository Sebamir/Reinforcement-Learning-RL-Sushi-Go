üç£ Reinforcement Learning - Sushi Go Master

Este repositorio contiene la implementaci√≥n de un agente de Aprendizaje por Refuerzo (RL) entrenado para jugar Sushi Go de forma profesional.
A diferencia de un bot basado en reglas, este agente utiliza PPO (Proximal Policy Optimization) y Self-Play para descubrir estrategias ganadoras por s√≠ mismo.

üöÄ Caracter√≠sticas Principales

Entorno de Juego Robusto
Implementaci√≥n personalizada bajo el est√°ndar de Gymnasium.

L√≥gica de Dependencia Temporal
El agente entiende que el Wasabi es una inversi√≥n a futuro, buscando maximizar el combo con el Nigiri de Calamar:

3
√ó
3
=
9
3√ó3=9 pts.

Competencia Multi-Agente
Sistema de puntuaci√≥n de Maki Rolls que incentiva a la IA a monitorear el progreso de los oponentes para asegurar el bono de mayor√≠a.

Entrenamiento Optimizado
Sistema de callbacks que gestiona evaluaciones peri√≥dicas, guarda el mejor modelo hist√≥rico y genera m√©tricas de rendimiento visuales.

üß† El Cerebro de la IA: Detalles T√©cnicos
El Reto del Wasabi

El Wasabi representa el problema cl√°sico de recompensa retardada en RL.
Jugar un Wasabi otorga 0 puntos inmediatos, pero triplica el siguiente Nigiri.

Para resolver esto:

Espacio de Observaci√≥n Extendido
Se a√±adieron bits de estado que indican si el jugador tiene un Wasabi Activo.

Modelado de Recompensa
Se configur√≥ la l√≥gica para que la red neuronal detecte que el valor esperado 
(
ùê∏
)
(E) de esperar un Calamar es mayor que conformarse con un Huevo de forma inmediata.

El Algoritmo PPO

Se utiliza Proximal Policy Optimization (PPO) debido a su estabilidad en entornos donde la pol√≠tica de juego cambia r√°pidamente (Self-Play).

üõ†Ô∏è Instalaci√≥n y Uso
1. Requisitos
pip install gymnasium stable-baselines3 shimmy gradio matplotlib numpy

2. Entrenamiento

Para iniciar un experimento de 500,000 pasos con evaluaci√≥n cada 25,000:

python -m src.train_optimized

3. Jugar contra el Agente

Lanza la interfaz de Gradio para poner a prueba tus habilidades:

python -m src.app_gradio

üè• Conexi√≥n con el Mundo Real: Aplicaciones en Salud

Este proyecto no es solo sobre sushi; es una simulaci√≥n de Toma de Decisiones Secuenciales bajo Incertidumbre, un campo cr√≠tico en la salud moderna:

Sinergia Farmacol√≥gica
La l√≥gica del Wasabi (una carta que potencia a otra) es an√°loga al modelado de tratamientos adyuvantes.
La IA aprende cu√°ndo una intervenci√≥n preparatoria maximiza la eficacia de una terapia principal posterior.

Triaje y Recursos Cr√≠ticos
La competencia por los Makis simula la asignaci√≥n de recursos limitados en un hospital.
La IA decide si ‚Äúinvertir‚Äù en un paciente/plato bas√°ndose en lo que el resto del sistema (oponentes) est√° haciendo.

Medicina Personalizada
El entrenamiento mediante Self-Play vuelve al modelo robusto ante distintos estilos de paciente (estrategias), permitiendo adaptarse a comportamientos no lineales en datos biom√©tricos.

üìà Pr√≥ximos Pasos

 L√≥gica de Puddings: Implementar la recompensa negativa por tener la menor cantidad de Puddings al final de la partida completa (3 rondas).

 Deep Q-Learning: Comparar el rendimiento de PPO contra DQN para este tipo de juegos de cartas.

 UI Mejorada: Renderizar im√°genes de cartas reales en la interfaz de Gradio.
